{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import os\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining functions to scrape from metacritic games\n",
    "\n",
    "def get_soup(url):\n",
    "    '''\n",
    "    Parse url with BeautifulSoup\n",
    "    \n",
    "    Inputs\n",
    "    ----\n",
    "    url (string)\n",
    "        url of page to parse\n",
    "    \n",
    "    Outputs\n",
    "    ----\n",
    "    soup (BeautifulSoup)\n",
    "        Soup object\n",
    "    '''\n",
    "\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "def genre_scraper(a):\n",
    "    '''\n",
    "    Get game genre from game page link\n",
    "    '''\n",
    "\n",
    "    gamelink = a['href']\n",
    "    url = f'https://www.metacritic.com{gamelink}'\n",
    "    soup = get_soup(url)\n",
    "    genres = soup.find('li',{'class': 'product_genre'})\n",
    "    if genres!= None:\n",
    "        genres = soup.find('li',{'class': 'product_genre'}).find_all('span', {'class': 'data'})\n",
    "    else:\n",
    "        return np.nan\n",
    "    return ', '.join(list(map(lambda x: x.text, genres)))\n",
    "\n",
    "def scraper(content):\n",
    "    '''\n",
    "    Extract information from content\n",
    "    Inputs\n",
    "    ----\n",
    "    content\n",
    "        content from a table in page\n",
    "\n",
    "    Outputs\n",
    "    ----\n",
    "    df (DataFrame)\n",
    "        dataframe with details in table\n",
    "    '''\n",
    "\n",
    "    df = pd.DataFrame(columns = ['name','platform','release_date','genre','metascore','user_score'])\n",
    "\n",
    "    table_rows = content.find_all('tr')\n",
    "    for tr in table_rows:\n",
    "        new_row = {}\n",
    "        if len(tr)<1:\n",
    "            continue\n",
    "        td = tr.find_all('td')\n",
    "        \n",
    "        #get game name\n",
    "        a = td[1].find('a', {\"class\":\"title\"})\n",
    "        new_row['name'] = a.find('h3').text\n",
    "        \n",
    "        genre = np.nan\n",
    "        tries = 0\n",
    "        while tries < 10 and type(genre)==float:\n",
    "            genre = genre_scraper(a)\n",
    "            tries += 1\n",
    "\n",
    "        if type(genre)==float:\n",
    "            print(f\"Giving up on genre scrape for {new_row['name']}\")\n",
    "\n",
    "        new_row['genre'] = genre\n",
    "        \n",
    "        #get release date\n",
    "        date = td[1].find('span',{\"class\":\"\"})\n",
    "        new_row['release_date'] = datetime.strptime(date.text, \"%B %d, %Y\")\n",
    "        \n",
    "        #get platform\n",
    "        p1 = td[1].find('div',{\"class\":\"platform\"})\n",
    "        new_row['platform'] = p1.find('span', {\"class\":\"data\"}).text.strip()\n",
    "\n",
    "        #get userscore\n",
    "        div_score = td[1].find('div', {\"class\":\"clamp-userscore\"})\n",
    "        user = div_score.find('div',{\"class\":\"metascore_w\"})\n",
    "        try:\n",
    "            new_row['user_score'] = float(user.text.strip())\n",
    "        except:\n",
    "            new_row['user_score'] = np.nan\n",
    "\n",
    "        #get metacore\n",
    "        score = td[1].find('div', {\"class\":\"metascore_w\"})\n",
    "        try:\n",
    "            new_row['metascore'] = float(score.text)\n",
    "        except:\n",
    "            new_row['metascore'] = np.nan\n",
    "\n",
    "        new_row = pd.DataFrame(new_row, index=[0])\n",
    "        df = pd.concat([new_row,df.loc[:]]).reset_index(drop=True)\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "def scrape_page(page): \n",
    "    '''\n",
    "    Scrapes the page from metacritic of games\n",
    "\n",
    "    Inputs\n",
    "    ----\n",
    "    page (int)\n",
    "        page number\n",
    "\n",
    "    Outputs\n",
    "    ----\n",
    "    dfs (list)\n",
    "        list of dataframes with page details\n",
    "    '''\n",
    "    print(page)\n",
    "    \n",
    "    #create list of tables in the webpage with game entries in each\n",
    "    url = f'https://www.metacritic.com/browse/games/score/metascore/all/all/filtered?sort=desc&view=detailed&page={page}'   \n",
    "    soup = get_soup(url)\n",
    "    content = soup.find_all('table')\n",
    "\n",
    "    #scrape each table\n",
    "    dfs = list(map(scraper,content))\n",
    "    return(dfs)\n",
    "\n",
    "def find_no_pages():\n",
    "    '''\n",
    "    Find total number of pages to scrape\n",
    "    '''\n",
    "\n",
    "    url = f'https://www.metacritic.com/browse/games/score/metascore/all/all/filtered?sort=desc&view=detailed&page={0}'\n",
    "    soup = get_soup(url)\n",
    "    num = soup.find('li',{'class': 'last_page'}).find('a', {'class': 'page_num'}).text\n",
    "    return int(num)\n",
    "\n",
    "def merge_data():\n",
    "    '''\n",
    "    Merge all tempdata to final file\n",
    "    '''\n",
    "    all_files = glob.glob(\"./tempdata/*.csv\")\n",
    "    df = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "    df.to_csv(\"metacritic_data_022023.csv\",index=False)\n",
    "\n",
    "def main():\n",
    "    '''\n",
    "    Scrape each page and save\n",
    "    '''\n",
    "    \n",
    "    n = find_no_pages()\n",
    "    for i in range(n):\n",
    "        scraped = scrape_page(i)\n",
    "        pd.concat(scraped).reset_index(drop=True).to_csv(f'./tempdata/page{i}.csv')\n",
    "    merge_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pangeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8343050fb055e0e7935e50e1c1b6aee05eb3278a7f1b5f6934655a9097874120"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
